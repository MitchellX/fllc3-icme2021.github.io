<!DOCTYPE html>
<html lang="en">

<head>
    <title>FLL3</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">


    <link href="https://fonts.googleapis.com/css?family=B612+Mono|Cabin:400,700&display=swap" rel="stylesheet">

    <link rel="stylesheet" href="fonts/icomoon/style.css">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css"
          integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">

    <link rel="stylesheet" href="css/jquery-ui.css">
    <link rel="stylesheet" href="css/owl.carousel.min.css">
    <link rel="stylesheet" href="css/owl.theme.default.min.css">
    <link rel="stylesheet" href="css/owl.theme.default.min.css">

    <link rel="stylesheet" href="css/jquery.fancybox.min.css">

    <link rel="stylesheet" href="fonts/flaticon/font/flaticon.css">

    <link rel="stylesheet" href="css/aos.css">
    <link href="css/jquery.mb.YTPlayer.min.css" media="all" rel="stylesheet" type="text/css">

    <link rel="stylesheet" href="css/style.css">
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <script>
        (function (i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r;
            i[r] = i[r] || function () {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o),
                m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m)
        })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-88572407-1', 'auto');
        ga('send', 'pageview');
    </script>
</head>

<body data-spy="scroll" data-target=".site-navbar-target" data-offset="300">

<div class="site-wrap">

    <div class="site-mobile-menu site-navbar-target">
        <div class="site-mobile-menu-header">
            <div class="site-mobile-menu-close mt-3">
                <span class="icon-close2 js-menu-toggle"></span>
            </div>
        </div>
        <div class="site-mobile-menu-body"></div>
    </div>

<!---------------------------导航栏------------------------------->
    <div class="site-navbar py-2 js-sticky-header site-navbar-target d-none pl-0 d-lg-block" role="banner">

        <div class="container">
            <div class="d-flex align-items-center">

                <div class="mr-auto">
                    <nav class="site-navigation position-relative text-right" role="navigation">
                        <ul class="site-menu main-menu js-clone-nav mr-auto d-none pl-0 d-lg-block">
                            <li class="active">
                                <a href="index.html" class="nav-link text-left">Home</a>
                            </li>
                            <li>
                                <a href="index.html#dates" class="nav-link text-left">Important dates</a>
                            </li>

                            <li>
                                <a href="index.html#organizer" class="nav-link text-left">organizer</a>
                            </li>

                            <li>
                                <a href="datasets.html" class="nav-link text-left">Datasets</a>
                            </li>

                            <li>
                                <a href="evaluation.html" class="nav-link text-left">evaluation</a>
                            </li>

                            <li class="nav-item dropdown">
                                <a class="nav-link dropdown-toggle" href="challenge.html" id="navbarDropdown"
                                   role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                                    Previous
                                </a>
                                <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                                    <a class="dropdown-item" href="https://fllc-icpr2020.github.io/home/">FLLC2_ICPR2020</a>
                                    <a class="dropdown-item" href="https://facial-landmarks-localization-challenge.github.io/#index">FLLC1_ICME2019</a>
                                </div>
                            </li>
                        </ul>
                    </nav>

                </div>

            </div>
        </div>

    </div>

</div>

<div class="site-blocks-cover overlay inner-page-cover" style="background-image: url('images/intro-background2.jpg');"
     data-stellar-background-ratio="0.5">
    <div class="container">
        <div class="row align-items-center justify-content-center">
            <div class="col-md-10 text-center" data-aos="fade-up">
<!--                <h3> The 2nd Learning from Imperfect Data (LID) Workshop</h3>-->
                <h1>The 3rd Grand Challenge of 106-Point Facial Landmark Localization</h1>
                <h3> ICME 2021</h3>
                <h3> July 5 2021, Shenzhen, China</h3>
            </div>
        </div>
    </div>
</div>

<div class="site-section">
    <div class="container">
        <div class="row">
             <div class="col-lg-12" id="schedule">



<!--                <div class="section-title">-->
<!--                    <h2>Schedule</h2>-->
<!--                </div>-->
<!--                <div class="trend-entry d-flex">-->
<!--                    <div class="trend-contents">-->
<!--                        <table class="table  table-hover" style="font-size:14px">-->
<!--                        <thead>-->
<!--                        <tr>-->
<!--                            <th scope="col"> Date    </th>-->
<!--                            <th scope="col"> June 14 Sunday 2020 <br/>(Pacific Time, SF Time) </th>-->
<!--                            <th scope="col"> Speaker</th>-->
<!--                            <th scope="col"> Topic</th>-->
<!--                        </tr>-->
<!--                        </thead>-->
<!--                        <tbody>-->
<!--                        <tr>-->
<!--                            <td>8:30-8:40</td>-->
<!--                            <td>Research Scientist at Stealth Mode AI Startup</td>-->
<!--                            <td>Shuai Zheng</td>-->
<!--                            <td>Opening Remark [<a href="slides/lidworkshopcvpr-opening.pdf">slide</a>][<a href="https://youtu.be/ve8NCkP2GbY">video</a>][<a href="https://www.bilibili.com/video/BV1BV41167kK">bilibili</a>]</td>-->
<!--                        </tr>-->
<!--                        <tr>-->
<!--                            <td>8:40-9:10</td>-->
<!--                            <td>Professor at Johns Hopkins University</td>-->
<!--                            <td>Alan Yuille</td>-->
<!--                            <td><strong>Invited talk 1:  </strong>[<a href="slides/lidworkshopcvpr-1.pdf">slide</a>][<a href="https://youtu.be/8T4Nvx3u2VE">video</a>][<a href="https://www.bilibili.com/video/BV1Ff4y1R7DJ">bilibili</a>] You Only Annotate Once, or Never</td>-->
<!--                        </tr>-->
<!--                        <tr>-->
<!--                            <td>9:10-9:40</td>-->
<!--                            <td>CEO at Ariel AI Inc. / Associate Professor UCL</td>-->
<!--                            <td>Iasonas Kokkinos</td>-->
<!--                            <td><strong>Invited talk 2:  </strong>[<a href="slides/lidworkshopcvpr-2.pdf">slide</a>][<a href="https://youtu.be/bP8jatY_OxY">video</a>][<a href="https://www.bilibili.com/video/BV1Yt4y1Q7GJ">bilibili</a>] Learning 3D object models from 2D images.</td>-->
<!--                        </tr>-->
<!--                        <tr>-->
<!--                            <td>9:50-10:20</td>-->
<!--                            <td>Director of Research at Mapillary</td>-->
<!--                            <td>Peter Kontschieder </td>-->
<!--                            <td><strong>Invited talk 3:  </strong>[<a href="slides/lidworkshopcvpr-3.pdf">slide</a>][<a href="https://youtu.be/KREJY1ABGA8">video</a>][<a href="https://www.bilibili.com/video/BV1MC4y1h7Jw">bilibili</a>] Computer Vision with Less Supervision</td>-->
<!--                        </tr>-->
<!--                        <tr>-->
<!--                            <td>10:30-11:00</td>-->
<!--                            <td>Research Scientist at Google</td>-->
<!--                            <td>Boqing Gong</td>-->
<!--                            <td><strong>Invited talk 4:  </strong>[<a href="slides/lidworkshopcvpr-4.pdf">slide</a>][<a href="https://youtu.be/0Z0DiyS39Sk">video</a>][<a href="https://www.bilibili.com/video/BV1SD4y1S73V">bilibili</a>] Towards Visual Recognition in the Wild: Long-Tailed Sources and Open Compound Targets</td>-->
<!--                        </tr>-->
<!--                        <tr>-->
<!--                            <td>11:10-11:40</td>-->
<!--                            <td>Staff Research Scientist at Facebook Research</td>-->
<!--                            <td>Zhicheng Yan</td>-->
<!--                            <td><strong>Invited talk 5:  </strong>[<a href="slides/lidworkshopcvpr-5.pdf">slide</a>][<a href="https://youtu.be/I8g0LlEER9g">video</a>][<a href="https://www.bilibili.com/video/BV1H5411e73y">bilibili</a>] Decoupling Representation and Classifier for Long-Tailed Recognition</td>-->
<!--                        </tr>-->
<!--                        <tr>-->
<!--                            <td>11:50-12:20</td>-->
<!--                            <td>ETH Zurich</td>-->
<!--                            <td>Guolei Sun</td>-->
<!--                            <td><strong>Oral 1:  </strong>[<a href="slides/Track-1-1-LID-wsss-cvl-eth.pptx">slide</a>][<a href="https://www.youtube.com/watch?v=XfQdw4-3-hg">video</a>][<a href="https://docs.google.com/document/d/1Eec63PPUePBPIPaiZjBo2fcdWA7hy26GdVZVf6jc8bQ/edit#heading=h.z9ischr02w32">Q&A</a>] The 1st Place of Track-1: Mining Cross-Image Semantics for Weakly-->
<!--Supervised Semantic Segmentation</td>-->
<!--                        </tr>-->
<!--                        <tr>-->
<!--                            <td>14:00-14:30</td>-->
<!--                            <td>Professor at University of California, Merced</td>-->
<!--                            <td>Ming-Hsuan Yang</td>-->
<!--                            <td><strong>Invited talk 6:  </strong>[<a href="slides/lidworkshopcvpr-6.pdf">slide</a>][<a href="https://youtu.be/5mn_566NU_4">video</a>][<a href="https://www.bilibili.com/video/BV1yZ4y1u7tB">bilibili</a>] Show, Match and Segment: Joint Weakly Supervised Learning of Semantic Matching and Object Co-segmentation</td>-->
<!--                        </tr>-->
<!--                        <tr>-->
<!--                            <td>14:40-15:10</td>-->
<!--                            <td>UCU & SoftServe Team</td>-->
<!--                            <td>Mariia Dobko</td>-->
<!--                            <td><strong>Oral 2:  </strong>[<a href="slides/Track-1-3-UCU & SoftServe Solution Presentation.pdf">slide</a>][<a href="https://youtu.be/mCrR7rhPMqs">video</a>][<a href="https://docs.google.com/document/d/1Eec63PPUePBPIPaiZjBo2fcdWA7hy26GdVZVf6jc8bQ/edit#heading=h.p0c0edojmlgg">Q&A</a>] The 3rd Place of Track-1: NoPeopleAllowed: The 3 step approach to weakly supervised semantic-->
<!--segmentation</td>-->
<!--                        </tr>-->
<!--                        <tr>-->
<!--                            <td>15:20-15:50</td>-->
<!--                            <td>Intel</td>-->
<!--                            <td>Hao Zhao</td>-->
<!--                            <td><strong>Oral 3:  </strong>[<a href="slides/Track-2-1-Unmix.pdf">slide</a>][<a href="https://www.youtube.com/watch?v=wac4daUcTIo&list=UUX6tsirfrt2W3vnDbKIy2Zw&index=4">video</a>][<a href="https://docs.google.com/document/d/1Eec63PPUePBPIPaiZjBo2fcdWA7hy26GdVZVf6jc8bQ/edit#heading=h.ls3cxq8tx8ct">Q&A</a>] The 1st Place of Track-2:Pointly supervised Scene Parsing with Uncertainty Mixture</td>-->
<!--                        </tr>-->
<!--                        <tr>-->
<!--                            <td>16:00-16:30</td>-->
<!--                            <td>Seoul National University</td>-->
<!--                            <td>Wonho Bae</td>-->
<!--                            <td><strong>Oral 4:  </strong>[<a href="slides/Track-3-1-lid2020_snuvl.pdf">slide</a>][<a href="https://www.youtube.com/watch?v=j_4Msm76-Y8&list=UUX6tsirfrt2W3vnDbKIy2Zw&index=1">video</a>][<a href="https://docs.google.com/document/d/1Eec63PPUePBPIPaiZjBo2fcdWA7hy26GdVZVf6jc8bQ/edit#heading=h.b72f14n87sic">Q&A</a>] The 1st Place of Track-3 & The 2nd Place of Track-1: Revisiting Class Activation Mapping for Learning from Imperfect Data</td>-->
<!--                        </tr>-->
<!--                        <tr>-->
<!--                            <td>16:40-17:10</td>-->
<!--                            <td>Beijing Jiaotong University & Mepro Team</td>-->
<!--                            <td>Chuangchuang Tan</td>-->
<!--                            <td><strong>Oral 5:  </strong>[<a href="slides/Track-3-2-LID2020presentation_Tan.pdf">slide</a>][<a href="https://www.youtube.com/watch?v=DqOV-4qUCqQ&list=UUX6tsirfrt2W3vnDbKIy2Zw&index=2">video</a>][<a href="https://docs.google.com/document/d/1Eec63PPUePBPIPaiZjBo2fcdWA7hy26GdVZVf6jc8bQ/edit#heading=h.iud5tsfagf95">Q&A</a>] The 2nd Place of Track-3: Dual Gradients Localization framework for-->
<!--Weakly Supervised Object Localization</td>-->
<!--                        </tr>-->
<!--                        <tr>-->
<!--                            <td>17:20-17:50</td>-->
<!--                            <td>Nanjing University Of Science and Technology & LEAP Group@PCA Lab</td>-->
<!--                            <td>Zhendong Wang </td>-->
<!--                            <td><strong>Oral 6:  </strong>[<a href="slides/Track-3-3.pdf">slide</a>][<a href="https://www.youtube.com/watch?v=sO2c_DyzVHo&list=UUX6tsirfrt2W3vnDbKIy2Zw&index=2">video</a>][<a href="https://www.bilibili.com/video/BV1Ff4y1R7DJ">bilibili</a>][<a href="https://docs.google.com/document/d/1Eec63PPUePBPIPaiZjBo2fcdWA7hy26GdVZVf6jc8bQ/edit#heading=h.mm8x1bvqv3me">Q&A</a>] The 3rd Place of Track-3: Weakly Supervised Object Localization</td>-->
<!--                        </tr>-->
<!--                        <tr>-->
<!--                            <td>17:50-18:20</td>-->
<!--                            <td>Professor at University of Adelaide</td>-->
<!--                            <td>Chunhua Shen</td>-->
<!--                            <td><strong>Invited talk 7:  </strong>[<a href="slides/lidworkshopcvpr-7.pdf">slide</a>] Single shot instance segmentation</td>-->
<!--                        </tr>-->
<!--                        <tr>-->
<!--                            <td>18:20-18:30</td>-->
<!--                            <td>Assistant Professor at University of Technology Sydney</td>-->
<!--                            <td>Yunchao Wei</td>-->
<!--                            <td colspan=3> Closing Remark [<a href="slides/lidworkshopcvpr-closing.pdf">slide</a>][<a href="https://youtu.be/dEP0Se3zzpc">video</a>][<a href="https://www.bilibili.com/video/BV1QK4y1s7ag">bilibili</a>]</td>-->
<!--                        </tr>-->
<!--                        </tbody>-->
<!--                    </table>-->
<!--                    </div>-->
<!--                </div>-->
            </div>

<!--             <div class="col-lg-12" id="results" style="padding-top:80px;margin-top:-80px;">-->
<!--                <div class="section-title">-->
<!--                    <h2>Challenge results</h2>-->
<!--                </div>-->
<!--                <div class="trend-entry d-flex">-->
<!--                    <table class="table">-->
<!--                        <thead>-->
<!--                        <tr>-->
<!--                            <th scope="col" colspan="2">  Track1: Weakly-supervised Semantic Segmentation Challenge</th>-->
<!--                        </tr>-->
<!--                        </thead>-->
<!--                        <tbody>-->
<!--                        <tr>-->
<!--                            <td>1st</td>-->
<!--                            <td>Guolei Sun, Wenguan Wang, Luc Van Gool. ETH Zurich </td>-->
<!--                        </tr>-->
<!--                        <tr>-->
<!--                            <td>2nd</td>-->
<!--                            <td>Wonho Bae*, Junhyug Noh*, Jinhwan Seo, and Gunhee Kim. Seoul National University, Vision & Learning Lab</td>-->
<!--                        </tr>-->
<!--                        <tr>-->
<!--                            <td>3rd</td>-->
<!--                            <td>Mariia Dobko, Ostap Viniavskyi, Oles Dobosevych. The Machine Learning Lab at Ukrainian Catholic University, SoftServe</td>-->
<!--                        </tr>-->
<!--                        </tbody>-->
<!--                    </table>-->
<!--                </div>-->
<!--                 <div class="trend-entry d-flex">-->
<!--                    <table class="table">-->
<!--                        <thead>-->
<!--                        <tr>-->
<!--                            <th scope="col" colspan="2"> Track2: Weakly-supervised Scene Parsing Challenge</th>-->
<!--                        </tr>-->
<!--                        </thead>-->
<!--                        <tbody>-->
<!--                        <tr>-->
<!--                            <td>1st</td>-->
<!--                            <td>Hao Zhao, Ming Lu, Anbang Yao, Yiwen Guo, Yurong Chen, Li Zhang. Tsinghua University</td>-->
<!--                        </tr>-->
<!--                        </tbody>-->
<!--                    </table>-->
<!--                 </div>-->
<!--                 <div class="trend-entry d-flex">-->
<!--                    <table class="table">-->
<!--                        <thead>-->
<!--                        <tr>-->
<!--                            <th scope="col" colspan="2">  Track3: Weakly-supervised Object Localization Challenge</th>-->
<!--                        </tr>-->
<!--                        </thead>-->
<!--                        <tbody>-->
<!--                        <tr>-->
<!--                            <td>1st</td>-->
<!--                            <td>Wonho Bae*, Junhyug Noh*, Jinhwan Seo, and Gunhee Kim. Seoul National University, Vision & Learning Lab</td>-->
<!--                        </tr>-->
<!--                        <tr>-->
<!--                            <td>2nd</td>-->
<!--                            <td>Chuangchuang Tan <sup>1*</sup>, Tao Ruan <sup>1*</sup>, Guanghua Gu <sup>2</sup>, Shikui Wei <sup>1</sup>, Yao Zhao<sup>1</sup>.   <sup>1</sup>Beijing Jiaotong University, <sup>2</sup>Yanshan University</td>-->
<!--                        </tr>-->
<!--                        <tr>-->
<!--                            <td>3rd</td>-->
<!--                            <td>Zhendong Wang, Zhenyuan Chen, Chen Gong. Nanjing University Of Science and Technology, LEAP Group@PCA Lab</td>-->
<!--                        </tr>-->
<!--                        </tbody>-->
<!--                    </table>-->
<!--                </div>-->

<!--            </div>-->

<!--            <div class="col-lg-10" id="papers" style="padding-top:80px;margin-top:-80px;">-->
<!--                <div class="section-title">-->
<!--                    <h2>Papers</h2>-->
<!--                </div>-->
<!--                <div class="trend-entry d-flex">-->
<!--                    <table>-->
<!--                        <tr>-->
<!--                            <td><strong> 1st (Track1) </strong> </td>-->
<!--                             <td>-->
<!--                                 <div>-->
<!--                                     <p>-->
<!--                                         Mining Cross-Image Semantics for Weakly Supervised Semantic Segmentation <strong class="text-danger"> (Best Paper Award)</strong> <br/>-->
<!--                                          Guolei Sun , Wenguan Wang , Luc Van Gool <br/>-->
<!--                                          The 2020 Learning from Imperfect Data (LID) Challenge - CVPR Workshops, 2020<br/>-->
<!--                                         [<a href="papers/Track-1-1-(cvpr2020)LID-wsss-cvl-eth.pdf">PDF</a>] [<a data-toggle="collapse"  href="#bib1" aria-expanded="false" aria-controls="bib1">BibTex</a>]-->
<!--                                         <div class="collapse" id="bib1">-->
<!--                                              <div class="panel panel-default panel-body">-->
<!--                                               @article{sun2020lid, <br/>-->
<!--                                                      &nbsp;&nbsp;&nbsp;&nbsp; author = {Sun, Guolei and Wang, Wenguan and Van Gool, Luc},<br/>-->
<!--                                                      &nbsp;&nbsp;&nbsp;&nbsp; title = {Mining Cross-Image Semantics for Weakly Supervised Semantic Segmentation},<br/>-->
<!--                                                      &nbsp;&nbsp;&nbsp;&nbsp; journal = {The 2020 Learning from Imperfect Data (LID) Challenge - CVPR Workshops},<br/>-->
<!--                                                      &nbsp;&nbsp;&nbsp;&nbsp; year = {2020}<br/>-->
<!--                                                    }-->
<!--                                              </div>-->
<!--                                         </div>-->
<!--                                     </p>-->
<!--                                 </div>-->
<!--                             </td>-->
<!--                        </tr>-->
<!--                         <tr>-->
<!--                             <td><strong>3rd (Track1)</strong> </td>-->
<!--                             <td>-->
<!--                                 <div>-->
<!--                                     <p>-->
<!--                                          NoPeopleAllowed: The Three-Step Approach to Weakly Supervised Semantic Segmentation <br/>-->
<!--                                          Mariia Dobko, Ostap Viniavskyi, Oles Dobosevych <br/>-->
<!--                                          The 2020 Learning from Imperfect Data (LID) Challenge - CVPR Workshops, 2020<br/>-->
<!--                                         [<a href="papers/Track-1-3-NoPeopleAllowed- The Three-Step Approach to Weakly Supervised SemanticSegmentation.pdf">PDF</a>] [<a data-toggle="collapse"  href="#bib2" aria-expanded="false" aria-controls="bib2">BibTex</a>]-->
<!--                                         <div class="collapse" id="bib2">-->
<!--                                              <div class="panel panel-default panel-body">-->
<!--                                               @article{dobko2020lid, <br/>-->
<!--                                                      &nbsp;&nbsp;&nbsp;&nbsp; author = {Dobko, Mariia  and Viniavskyi, Ostap and Dobosevych, Oles}, <br/>-->
<!--                                                      &nbsp;&nbsp;&nbsp;&nbsp; title = {NoPeopleAllowed: The Three-Step Approach to Weakly Supervised Semantic Segmentation},<br/>-->
<!--                                                      &nbsp;&nbsp;&nbsp;&nbsp; journal = {The 2020 Learning from Imperfect Data (LID) Challenge - CVPR Workshops},<br/>-->
<!--                                                      &nbsp;&nbsp;&nbsp;&nbsp; year = {2020}<br/>-->
<!--                                                    }-->
<!--                                              </div>-->
<!--                                         </div>-->
<!--                                     </p>-->
<!--                                 </div>-->
<!--                             </td>-->
<!--                        </tr>-->
<!--                         <tr>-->
<!--                             <td> <strong> 1st (Track2) </strong></td>-->
<!--                             <td>-->
<!--                                 <div>-->
<!--                                     <p>-->
<!--                                          Pointly-supervised Scene Parsing with Uncertainty Mixture <br/>-->
<!--                                          Hao Zhao, Ming Lu, Anbang Yao, Yiwen Guo, Yurong Chen, Li Zhang <br/>-->
<!--                                          The 2020 Learning from Imperfect Data (LID) Challenge - CVPR Workshops, 2020<br/>-->
<!--                                         [<a href="papers/Track-2-1-unmix-lid.pdf">PDF</a>] [<a data-toggle="collapse"  href="#bib3" aria-expanded="false" aria-controls="bib3">BibTex</a>]-->
<!--                                         <div class="collapse" id="bib3">-->
<!--                                              <div class="panel panel-default panel-body">-->
<!--                                               @article{zhao2020lid, <br/>-->
<!--                                                      &nbsp;&nbsp;&nbsp;&nbsp; author = {Zhao, Hao and Lu, Ming and Yao, Anbang and Guo, Yiwen and Chen, Yurong, Zhang, Li}, <br/>-->
<!--                                                      &nbsp;&nbsp;&nbsp;&nbsp; title = {Pointly-supervised Scene Parsing with Uncertainty Mixture},<br/>-->
<!--                                                      &nbsp;&nbsp;&nbsp;&nbsp; journal = {The 2020 Learning from Imperfect Data (LID) Challenge - CVPR Workshops},<br/>-->
<!--                                                      &nbsp;&nbsp;&nbsp;&nbsp; year = {2020}<br/>-->
<!--                                                    }-->
<!--                                              </div>-->
<!--                                         </div>-->
<!--                                     </p>-->
<!--                                 </div>-->
<!--                             </td>-->
<!--                        </tr>-->
<!--                         <tr>-->
<!--                             <td> <strong>1st (Track3)</strong></td>-->
<!--                             <td>-->
<!--                                  <div>-->
<!--                                     <p>-->
<!--                                          Revisiting Class Activation Mapping for Learning from Imperfect Data <br/>-->
<!--                                          Wonho Bae*, Junhyug Noh*, Jinhwan Seo, Gunhee Kim <br/>-->
<!--                                          The 2020 Learning from Imperfect Data (LID) Challenge - CVPR Workshops, 2020<br/>-->
<!--                                         [<a href="papers/Track-3-1-lid_paper_snuvl.pdf">PDF</a>] [<a data-toggle="collapse"  href="#bib4" aria-expanded="false" aria-controls="bib4">BibTex</a>]-->
<!--                                         <div class="collapse" id="bib4">-->
<!--                                              <div class="panel panel-default panel-body">-->
<!--                                               @article{bae2020lid, <br/>-->
<!--                                                      &nbsp;&nbsp;&nbsp;&nbsp; author = {Bae, Wonho and Noh, Junhyug and Seo, Jinhwan  and Kim, Gunhee}, <br/>-->
<!--                                                      &nbsp;&nbsp;&nbsp;&nbsp; title = {Revisiting Class Activation Mapping for Learning from Imperfect Data},<br/>-->
<!--                                                      &nbsp;&nbsp;&nbsp;&nbsp; journal = {The 2020 Learning from Imperfect Data (LID) Challenge - CVPR Workshops},<br/>-->
<!--                                                      &nbsp;&nbsp;&nbsp;&nbsp; year = {2020}<br/>-->
<!--                                                    }-->
<!--                                              </div>-->
<!--                                         </div>-->
<!--                                     </p>-->
<!--                                 </div>-->
<!--                             </td>-->
<!--                        </tr>-->
<!--                         <tr>-->
<!--                             <td><strong>5th (Track3)</strong></td>-->
<!--                             <td>-->
<!--                                 <div>-->
<!--                                     <p>-->
<!--                                          Object Localization with weakly supervised learning <br/>-->
<!--                                          Jun He, Huanqing Yan <br/>-->
<!--                                          The 2020 Learning from Imperfect Data (LID) Challenge - CVPR Workshops, 2020<br/>-->
<!--                                         [<a href="papers/Object Localization with weakly supervised learning.pdf">PDF</a>] [<a data-toggle="collapse"  href="#bib5" aria-expanded="false" aria-controls="bib5">BibTex</a>]-->
<!--                                         <div class="collapse" id="bib5">-->
<!--                                              <div class="panel panel-default panel-body">-->
<!--                                               @article{he2020lid, <br/>-->
<!--                                                      &nbsp;&nbsp;&nbsp;&nbsp; author = {He, Jun and Yan, Huanqing}, <br/>-->
<!--                                                      &nbsp;&nbsp;&nbsp;&nbsp; title = {Object Localization with weakly supervised learning},<br/>-->
<!--                                                      &nbsp;&nbsp;&nbsp;&nbsp; journal = {The 2020 Learning from Imperfect Data (LID) Challenge - CVPR Workshops},<br/>-->
<!--                                                      &nbsp;&nbsp;&nbsp;&nbsp; year = {2020}<br/>-->
<!--                                                    }-->
<!--                                              </div>-->
<!--                                         </div>-->
<!--                                     </p>-->
<!--                                 </div>-->
<!--                             </td>-->
<!--                        </tr>-->
<!--                    </table>-->
<!--                </div>-->
<!--            </div>-->


<!------------------------  overview  ----------------------->
            <div class="col-lg-12">
                <div class="section-title">
                    <h2>Overview</h2>
                </div>
                <div class="trend-entry d-flex">
                    <div class="trend-contents">
                        <p>

                            &emsp;&emsp; Due to the global pandemic of COVID-19, people are recommended to wear facial mask for the sake of health and safety and the situation will continue in the long run. This apparently makes conventional facial landmark localization unfaithful (inaccurate) and inefficient. However, facial landmark localization is a very crucial step of facial recognition technology, which is very helpful in tracking the close contacts of COVID-19 patients to prevent the spread of the virus. Besides, it is also wildly used in facial pose estimation, face image synthesis, and etc. Therefore, we are hosting the 3rd grand challenge of 106-point facial landmark localization in conjunction with ICME 2021, aiming to improve the accuracy and efficiency of facial landmark localization in the real-world situation, especially on the masked faces.
                            <br>
                            &emsp;&emsp; The 1st and 2nd 106-point facial landmark localization competitions were held in conjunctive with ICME2019 and ICPR2020, respectively. There are more than 400 teams taking part in the competitions, e.g., Tinghua University, National University of Singapore, University of Michigan. Different from the prior two challenges, the 2021 edition contains more than 50,000 images of three kinds, real-masked, virtual-masked, and non-masked, which are largely varied in identity, pose, expression, and occlusion. In addition, a strict limitation of model weights is required for computational efficiency (the upper bound of computational complexity is 100MFLOPs, and the upper bound of model size is 2MB). We sincerely invite academic and industrial practitioners to participate in and together push the frontier along this direction.

                        </p>
                    </div>
                </div>
            </div>





<!------------------------  import dates  --------------------->

            <div class="col-lg-12" id="dates" style="padding-top:80px;margin-top:-80px;">
                <div class="section-title">

                    <br><br><br>
                    <h2>Important Dates</h2>
                </div>
                <div class="trend-entry d-flex"> 
                    <table class="table table-striped">
                        <thead>
                        <tr>
                            <th scope="col"> Description</th>
                            <th scope="col"> Date</th>
                        </tr>
                        </thead>
                        <tbody> 
                        <tr>
                            <td>Challenge Begin</td>
                            <td>11:59PM Pacific Time March 1, 2021</td>
                        </tr>

                        <tr>
                            <td>Validation phase</td>
                            <td>11:59PM Pacific Time March 1, 2021</td>
                        </tr>

                        <tr>
                            <td>Release test images</td>
                            <td>11:59PM Pacific Time April 1, 2021</td>
                        </tr>

                        <tr>
                            <td>Model & Paper submission deadline</td>
                            <td>11:59PM Pacific Time April 7, 2021</td>
                        </tr>

                        <tr>
                            <td>Final evaluation results & Paper acceptance announcement</td>
                            <td>11:59PM Pacific Time April 30, 2021</td>
                        </tr>

                        <tr>
                            <td>Camera-ready paper submission deadline</td>
                            <td>11:59PM Pacific Time May 7, 2021</td>
                        </tr>
                      <!--   <tr>
                            <td>Poster</td>
                            <td>10:00-11:00, June 16, 2020</td>
                        </tr> -->
                        </tbody>
                    </table>
                </div>

            </div>



<!------------------------------ award  ------------------------------------------>


        <div class="col-lg-12" id="awards" style="padding-top:80px;margin-top:-80px;">
                <div class="section-title">
                <br><br><br>

                    <h2>awards</h2>
                </div>

                <div class="row justify-content-md-center">
                    <div class="section-title">
                        <img src="images/prize.png" class="icon-align-center" width="100%">
                    </div>

                </div>
        </div>



<!----------------------------  organizer  ---------------------------------------->

            <div class="col-lg-12" id="organizer" style="padding-top:80px;margin-top:-80px;">
                <div class="section-title">

                    <br><br><br>
                    <h2>organizers</h2>
                </div>
                <div class="row justify-content-md-center">

                    <div class="col-md-3">
                        <div class="card">
                            <img src="images/wyc2.jpg" width="100%"/>
                            <div class="post-meta">
                                <span class="d-block"><a href="https://github.com/JDAI-CV/lapa-dataset">Yinglu Liu</a> </span>
                                <span class="date-read">  DJ AI Research</span>
                            </div>
                        </div>
                    </div>

                    <div class="col-md-3">
                        <div class="card">
                            <img src="images/shuai_zheng.jpg" width="100%"/>
                            <div class="post-meta">
                                <span class="d-block"><a href="https://mitchellx.github.io/">Mingcan Xiang</a> </span>
                                <span class="date-read">  DJ AI Research</span>
                            </div>
                        </div>
                    </div>

                    <div class="col-md-3">
                        <div class="card">
                            <img src="images/CMMC.jpg" width="100%"/>
                            <div class="post-meta">
                                <span class="d-block"><a href="https://sites.google.com/view/hailin-shi">Hailin Shi</a> </span>
                                <span class="date-read">  DJ AI Research</span>
                            </div>
                        </div>
                    </div>

                    <div class="col-md-3">
                        <div class="card">
                            <img src="images/hangzhao.jpg" width="100%"/>
                            <div class="post-meta">
                                <span class="d-block"><a href="http://liuwu.weebly.com/">Wu Liu</a> </span>
                                <span class="date-read">  DJ AI Research</span>
                            </div>
                        </div>
                    </div>

                    <div class="col-md-3">
                        <div class="card">
                            <img src="images/hangzhao.jpg" width="100%"/>
                            <div class="post-meta">
                                <span class="d-block"><a href="http://www.cbsr.ia.ac.cn/users/xiangyuzhu/">Xiangyu Zhu</a> </span>
                                <span class="date-read">  Institute of Automation, CAS</span>
                            </div>
                        </div>
                    </div>

                </div>

<!--                <div class="row" style="margin-top: 40px">-->
<!--                    <div class="col-md-3">-->
<!--                        <div class="card">-->
<!--&lt;!&ndash;                             <img src="LID2019/img/liuting.jpg" width="100%"/> &ndash;&gt;-->
<!--                            <div class="post-meta">-->
<!--                                <span class="d-block"> Ting Liu </span>-->
<!--                                <span >Webmaster</span>-->
<!--                            </div>-->
<!--                        </div>-->
<!--                    </div>-->
<!--                </div>-->
            </div>
        </div>











<!------------------------------ sponsor  ------------------------------------------>


                <div class="row justify-content-md-center">
                    <div class="section-title">
                        <br><br><br>
                        <img src="images/logo.png" class="icon-align-center" width="100%">
                    </div>

                </div>




<!--        ----------------------------email-------------------------------->
<br><br>
 <p style="text-align: center">Please feel free to contact us if you have any questions! &nbsp&nbsp <strong>fllc3_icme@163.com</strong> </p>






<!-------------------------------   boarder  ---------------------------------------->
        <div class="col-lg-12">
            <div style="display:inline-block;width:500px;">
                <script type="text/javascript" src="//rc.rev
            olvermaps.com/0/0/7.js?i=2hlmeh3dic1&amp;m=0&amp;c=ff0000&amp;cr1=ffffff&amp;br=19&amp;sx=0"
                        async="async"></script>
            </div>
        </div>
    </div>
</div>
<!-- END section -->


<div class="footer">
    <div class="container">
        <div class="row">
            <div class="col-12">
                <div class="copyright">
                    <p>
                        <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
                        Copyright &copy;<script>document.write(new Date().getFullYear());</script>
                        All rights reserved | This template is made with <i class="icon-heart text-danger"
                                                                            aria-hidden="true"></i> by <a
                            href="https://colorlib.com" target="_blank">Colorlib</a>
                        <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
                    </p>
                </div>
            </div>
        </div>
    </div>
</div>


</div>
<!-- .site-wrap -->


<!-- loader -->
<div id="loader" class="show fullscreen">
    <svg class="circular" width="48px" height="48px">
        <circle class="path-bg" cx="24" cy="24" r="22" fill="none" stroke-width="4" stroke="#eeeeee"/>
        <circle class="path" cx="24" cy="24" r="22" fill="none" stroke-width="4" stroke-miterlimit="10"
                stroke="#ff5e15"/>
    </svg>
</div>

<script src="js/jquery-3.3.1.min.js"></script>
<script src="js/jquery-migrate-3.0.1.min.js"></script>
<script src="js/jquery-ui.js"></script>
<script src="js/popper.min.js"></script>
<script src="js/bootstrap.min.js"></script>
<script src="js/owl.carousel.min.js"></script>
<script src="js/jquery.stellar.min.js"></script>
<script src="js/jquery.countdown.min.js"></script>
<script src="js/bootstrap-datepicker.min.js"></script>
<script src="js/jquery.easing.1.3.js"></script>
<script src="js/aos.js"></script>
<script src="js/jquery.fancybox.min.js"></script>
<script src="js/jquery.sticky.js"></script>
<script src="js/jquery.mb.YTPlayer.min.js"></script>


<script src="js/main.js"></script>

</body>

</html>
